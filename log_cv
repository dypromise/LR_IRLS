Training model with lambda: 0.001000
Iteration: 1, Loss: 20322.622259, lambda^2: 16165.871410
Iteration: 2, Loss: 11181.526447, lambda^2: 2136.294686
Iteration: 3, Loss: 9869.135621, lambda^2: 566.373994
Iteration: 4, Loss: 9526.294347, lambda^2: 116.147099
Iteration: 5, Loss: 9458.956593, lambda^2: 11.736883
Iteration: 6, Loss: 9452.543875, lambda^2: 0.431600
Iteration: 7, Loss: 9452.286484, lambda^2: 0.062347
Iteration: 8, Loss: 9452.236058, lambda^2: 0.014066
Iteration: 9, Loss: 9452.219994, lambda^2: 0.002000
Iteration: 1, Loss: 20336.263046, lambda^2: 16201.730833
Iteration: 2, Loss: 11179.169576, lambda^2: 2126.409726
Iteration: 3, Loss: 9873.231592, lambda^2: 562.614207
Iteration: 4, Loss: 9532.593100, lambda^2: 115.498168
Iteration: 5, Loss: 9465.673161, lambda^2: 11.457531
Iteration: 6, Loss: 9459.425021, lambda^2: 0.404325
Iteration: 7, Loss: 9459.182616, lambda^2: 0.058971
Iteration: 8, Loss: 9459.134342, lambda^2: 0.012983
Iteration: 9, Loss: 9459.119079, lambda^2: 0.001740
Iteration: 1, Loss: 20286.320708, lambda^2: 16145.566288
Iteration: 2, Loss: 11154.896618, lambda^2: 2127.751626
Iteration: 3, Loss: 9848.572388, lambda^2: 560.205621
Iteration: 4, Loss: 9509.536787, lambda^2: 114.553585
Iteration: 5, Loss: 9443.145018, lambda^2: 11.491982
Iteration: 6, Loss: 9436.866606, lambda^2: 0.419990
Iteration: 7, Loss: 9436.615608, lambda^2: 0.059748
Iteration: 8, Loss: 9436.566726, lambda^2: 0.013230
Iteration: 9, Loss: 9436.551257, lambda^2: 0.001806
Iteration: 1, Loss: 20305.948181, lambda^2: 16156.022700
Iteration: 2, Loss: 11169.527765, lambda^2: 2130.262273
Iteration: 3, Loss: 9861.724497, lambda^2: 558.713952
Iteration: 4, Loss: 9523.931606, lambda^2: 112.444795
Iteration: 5, Loss: 9458.885193, lambda^2: 10.863015
Iteration: 6, Loss: 9452.963121, lambda^2: 0.406328
Iteration: 7, Loss: 9452.714166, lambda^2: 0.067487
Iteration: 8, Loss: 9452.658470, lambda^2: 0.014679
Iteration: 9, Loss: 9452.640951, lambda^2: 0.002033
Iteration: 1, Loss: 20312.005860, lambda^2: 16217.381412
Iteration: 2, Loss: 11141.010020, lambda^2: 2145.586972
Iteration: 3, Loss: 9822.428996, lambda^2: 572.295279
Iteration: 4, Loss: 9475.731141, lambda^2: 118.201893
Iteration: 5, Loss: 9407.216777, lambda^2: 11.876643
Iteration: 6, Loss: 9400.730509, lambda^2: 0.425237
Iteration: 7, Loss: 9400.477922, lambda^2: 0.058629
Iteration: 8, Loss: 9400.430247, lambda^2: 0.013406
Iteration: 9, Loss: 9400.415142, lambda^2: 0.001957
Iteration: 1, Loss: 20327.972192, lambda^2: 16172.383862
Iteration: 2, Loss: 11185.700500, lambda^2: 2124.579106
Iteration: 3, Loss: 9881.181812, lambda^2: 560.095740
Iteration: 4, Loss: 9542.216314, lambda^2: 114.475838
Iteration: 5, Loss: 9475.880714, lambda^2: 11.407365
Iteration: 6, Loss: 9469.657469, lambda^2: 0.404980
Iteration: 7, Loss: 9469.415117, lambda^2: 0.059074
Iteration: 8, Loss: 9469.367017, lambda^2: 0.013288
Iteration: 9, Loss: 9469.351757, lambda^2: 0.001877
Iteration: 1, Loss: 20278.456682, lambda^2: 16118.761890
Iteration: 2, Loss: 11158.623647, lambda^2: 2140.085346
Iteration: 3, Loss: 9843.770979, lambda^2: 567.990627
Iteration: 4, Loss: 9499.992143, lambda^2: 115.683170
Iteration: 5, Loss: 9433.050717, lambda^2: 11.243893
Iteration: 6, Loss: 9426.922561, lambda^2: 0.395676
Iteration: 7, Loss: 9426.684772, lambda^2: 0.058196
Iteration: 8, Loss: 9426.636913, lambda^2: 0.012668
Iteration: 9, Loss: 9426.621795, lambda^2: 0.001665
Iteration: 1, Loss: 20301.131974, lambda^2: 16179.811554
Iteration: 2, Loss: 11150.021340, lambda^2: 2138.257822
Iteration: 3, Loss: 9836.864863, lambda^2: 564.200929
Iteration: 4, Loss: 9495.456253, lambda^2: 114.796518
Iteration: 5, Loss: 9429.022717, lambda^2: 11.108903
Iteration: 6, Loss: 9422.974031, lambda^2: 0.379382
Iteration: 7, Loss: 9422.742840, lambda^2: 0.056282
Iteration: 8, Loss: 9422.695018, lambda^2: 0.012360
Iteration: 9, Loss: 9422.680295, lambda^2: 0.001736
Iteration: 1, Loss: 20314.554123, lambda^2: 16209.185876
Iteration: 2, Loss: 11148.896287, lambda^2: 2136.042526
Iteration: 3, Loss: 9837.049123, lambda^2: 566.087561
Iteration: 4, Loss: 9494.023509, lambda^2: 118.004385
Iteration: 5, Loss: 9425.537215, lambda^2: 11.990993
Iteration: 6, Loss: 9419.000291, lambda^2: 0.413273
Iteration: 7, Loss: 9418.755993, lambda^2: 0.059235
Iteration: 8, Loss: 9418.708988, lambda^2: 0.013519
Iteration: 9, Loss: 9418.693928, lambda^2: 0.001925
Iteration: 1, Loss: 20271.734101, lambda^2: 16092.847126
Iteration: 2, Loss: 11166.534074, lambda^2: 2133.134170
Iteration: 3, Loss: 9856.447374, lambda^2: 563.401925
Iteration: 4, Loss: 9515.523068, lambda^2: 114.810566
Iteration: 5, Loss: 9449.033726, lambda^2: 11.340256
Iteration: 6, Loss: 9442.851399, lambda^2: 0.387920
Iteration: 7, Loss: 9442.620361, lambda^2: 0.053028
Iteration: 8, Loss: 9442.576272, lambda^2: 0.011289
Iteration: 9, Loss: 9442.562392, lambda^2: 0.001410
Accuarcy with lambda_ = 0.001000 is 0.154652
Training model with lambda: 0.003000
Iteration: 1, Loss: 20307.381827, lambda^2: 16179.126912
Iteration: 2, Loss: 11158.065545, lambda^2: 2134.621174
Iteration: 3, Loss: 9847.334868, lambda^2: 561.220480
Iteration: 4, Loss: 9507.978949, lambda^2: 113.005716
Iteration: 5, Loss: 9442.579748, lambda^2: 10.922382
Iteration: 6, Loss: 9436.607517, lambda^2: 0.365784
Iteration: 7, Loss: 9436.371733, lambda^2: 0.041774
Iteration: 8, Loss: 9436.327360, lambda^2: 0.006047
Iteration: 1, Loss: 20318.735462, lambda^2: 16143.719396
Iteration: 2, Loss: 11191.206309, lambda^2: 2124.272755
Iteration: 3, Loss: 9886.996007, lambda^2: 559.214681
Iteration: 4, Loss: 9548.513317, lambda^2: 114.575042
Iteration: 5, Loss: 9482.081523, lambda^2: 11.391903
Iteration: 6, Loss: 9475.850846, lambda^2: 0.368560
Iteration: 7, Loss: 9475.614574, lambda^2: 0.038240
Iteration: 8, Loss: 9475.572482, lambda^2: 0.005442
Iteration: 1, Loss: 20316.777743, lambda^2: 16100.595868
Iteration: 2, Loss: 11215.094973, lambda^2: 2110.291827
Iteration: 3, Loss: 9920.035366, lambda^2: 551.880955
Iteration: 4, Loss: 9586.290808, lambda^2: 111.651572
Iteration: 5, Loss: 9521.599343, lambda^2: 11.048480
Iteration: 6, Loss: 9515.536450, lambda^2: 0.382314
Iteration: 7, Loss: 9515.283882, lambda^2: 0.038636
Iteration: 8, Loss: 9515.237363, lambda^2: 0.005043
Iteration: 1, Loss: 20305.486151, lambda^2: 16152.221653
Iteration: 2, Loss: 11169.025394, lambda^2: 2142.323431
Iteration: 3, Loss: 9852.614989, lambda^2: 569.837152
Iteration: 4, Loss: 9507.530905, lambda^2: 117.240356
Iteration: 5, Loss: 9439.544900, lambda^2: 11.765766
Iteration: 6, Loss: 9433.100288, lambda^2: 0.388320
Iteration: 7, Loss: 9432.853920, lambda^2: 0.036657
Iteration: 8, Loss: 9432.812326, lambda^2: 0.004869
Iteration: 1, Loss: 20295.738797, lambda^2: 16137.590125
Iteration: 2, Loss: 11168.437676, lambda^2: 2131.755353
Iteration: 3, Loss: 9859.523432, lambda^2: 560.964200
Iteration: 4, Loss: 9520.221615, lambda^2: 113.227877
Iteration: 5, Loss: 9454.735266, lambda^2: 10.797907
Iteration: 6, Loss: 9448.839054, lambda^2: 0.350628
Iteration: 7, Loss: 9448.611823, lambda^2: 0.039733
Iteration: 8, Loss: 9448.568590, lambda^2: 0.005752
Iteration: 1, Loss: 20343.552364, lambda^2: 16218.928518
Iteration: 2, Loss: 11176.364612, lambda^2: 2128.465087
Iteration: 3, Loss: 9869.671595, lambda^2: 558.577178
Iteration: 4, Loss: 9531.911997, lambda^2: 112.467255
Iteration: 5, Loss: 9466.840050, lambda^2: 10.873869
Iteration: 6, Loss: 9460.894083, lambda^2: 0.351693
Iteration: 7, Loss: 9460.667909, lambda^2: 0.034230
Iteration: 8, Loss: 9460.628125, lambda^2: 0.004354
Iteration: 1, Loss: 20339.039722, lambda^2: 16251.959730
Iteration: 2, Loss: 11152.965443, lambda^2: 2136.996200
Iteration: 3, Loss: 9840.044030, lambda^2: 568.558661
Iteration: 4, Loss: 9495.482451, lambda^2: 118.641521
Iteration: 5, Loss: 9426.519833, lambda^2: 12.682565
Iteration: 6, Loss: 9419.481922, lambda^2: 0.758134
Iteration: 7, Loss: 9418.993698, lambda^2: 0.160769
Iteration: 8, Loss: 9418.864244, lambda^2: 0.037828
Iteration: 9, Loss: 9418.823432, lambda^2: 0.004952
Iteration: 1, Loss: 20285.552201, lambda^2: 16087.194181
Iteration: 2, Loss: 11186.078012, lambda^2: 2120.155732
Iteration: 3, Loss: 9885.199148, lambda^2: 552.417917
Iteration: 4, Loss: 9551.420918, lambda^2: 110.110925
Iteration: 5, Loss: 9487.751175, lambda^2: 10.785535
Iteration: 6, Loss: 9481.785644, lambda^2: 0.674378
Iteration: 7, Loss: 9481.346534, lambda^2: 0.156798
Iteration: 8, Loss: 9481.220856, lambda^2: 0.036366
Iteration: 9, Loss: 9481.181039, lambda^2: 0.004657
Iteration: 1, Loss: 20277.083712, lambda^2: 16085.971182
Iteration: 2, Loss: 11175.304141, lambda^2: 2138.384645
Iteration: 3, Loss: 9861.374449, lambda^2: 568.779935
Iteration: 4, Loss: 9516.797725, lambda^2: 118.086847
Iteration: 5, Loss: 9448.213706, lambda^2: 12.150533
Iteration: 6, Loss: 9441.559159, lambda^2: 0.391581
Iteration: 7, Loss: 9441.315166, lambda^2: 0.035766
Iteration: 8, Loss: 9441.276731, lambda^2: 0.005426
Iteration: 1, Loss: 20295.590284, lambda^2: 16125.796922
Iteration: 2, Loss: 11174.554439, lambda^2: 2131.439203
Iteration: 3, Loss: 9865.860953, lambda^2: 560.107383
Iteration: 4, Loss: 9527.243458, lambda^2: 112.271405
Iteration: 5, Loss: 9462.340466, lambda^2: 10.603421
Iteration: 6, Loss: 9456.552945, lambda^2: 0.340543
Iteration: 7, Loss: 9456.330948, lambda^2: 0.039827
Iteration: 8, Loss: 9456.288084, lambda^2: 0.005869
Accuarcy with lambda_ = 0.003000 is 0.149217
Training model with lambda: 0.010000
Iteration: 1, Loss: 20282.452186, lambda^2: 16106.781395
Iteration: 2, Loss: 11170.794695, lambda^2: 2128.981362
Iteration: 3, Loss: 9863.803934, lambda^2: 557.452944
Iteration: 4, Loss: 9526.850854, lambda^2: 110.714359
Iteration: 5, Loss: 9462.899687, lambda^2: 10.016697
Iteration: 6, Loss: 9457.398739, lambda^2: 0.256354
Iteration: 7, Loss: 9457.205330, lambda^2: 0.015389
Iteration: 8, Loss: 9457.176902, lambda^2: 0.000611
Iteration: 1, Loss: 20284.788841, lambda^2: 16149.881683
Iteration: 2, Loss: 11148.469730, lambda^2: 2138.517061
Iteration: 3, Loss: 9835.142275, lambda^2: 564.357519
Iteration: 4, Loss: 9493.359554, lambda^2: 116.457484
Iteration: 5, Loss: 9425.690575, lambda^2: 11.750954
Iteration: 6, Loss: 9419.215383, lambda^2: 0.318182
Iteration: 7, Loss: 9418.993497, lambda^2: 0.013341
Iteration: 8, Loss: 9418.967071, lambda^2: 0.000458
Iteration: 1, Loss: 20311.361113, lambda^2: 16151.154664
Iteration: 2, Loss: 11180.303513, lambda^2: 2122.956222
Iteration: 3, Loss: 9876.706206, lambda^2: 559.479979
Iteration: 4, Loss: 9538.011141, lambda^2: 114.402846
Iteration: 5, Loss: 9471.604540, lambda^2: 11.286551
Iteration: 6, Loss: 9465.365034, lambda^2: 0.307621
Iteration: 7, Loss: 9465.139960, lambda^2: 0.013969
Iteration: 8, Loss: 9465.112262, lambda^2: 0.000495
Iteration: 1, Loss: 20283.115064, lambda^2: 16126.327034
Iteration: 2, Loss: 11160.686271, lambda^2: 2133.094441
Iteration: 3, Loss: 9850.819138, lambda^2: 561.409344
Iteration: 4, Loss: 9511.217173, lambda^2: 112.940103
Iteration: 5, Loss: 9445.833032, lambda^2: 10.625850
Iteration: 6, Loss: 9439.960325, lambda^2: 0.285296
Iteration: 7, Loss: 9439.738142, lambda^2: 0.014109
Iteration: 8, Loss: 9439.708393, lambda^2: 0.000496
Iteration: 1, Loss: 20261.895115, lambda^2: 16081.751652
Iteration: 2, Loss: 11161.465510, lambda^2: 2134.136887
Iteration: 3, Loss: 9850.677840, lambda^2: 564.689627
Iteration: 4, Loss: 9508.634134, lambda^2: 116.486381
Iteration: 5, Loss: 9440.971618, lambda^2: 11.690955
Iteration: 6, Loss: 9434.517303, lambda^2: 0.326278
Iteration: 7, Loss: 9434.284441, lambda^2: 0.014567
Iteration: 8, Loss: 9434.255796, lambda^2: 0.000529
Iteration: 1, Loss: 20325.517050, lambda^2: 16205.621118
Iteration: 2, Loss: 11163.051961, lambda^2: 2132.298988
Iteration: 3, Loss: 9853.969806, lambda^2: 559.918979
Iteration: 4, Loss: 9515.127931, lambda^2: 114.223540
Iteration: 5, Loss: 9448.781202, lambda^2: 11.763855
Iteration: 6, Loss: 9442.200848, lambda^2: 0.621068
Iteration: 7, Loss: 9441.757347, lambda^2: 0.100053
Iteration: 8, Loss: 9441.650177, lambda^2: 0.012431
Iteration: 9, Loss: 9441.622537, lambda^2: 0.000351
Iteration: 1, Loss: 20311.805514, lambda^2: 16158.216789
Iteration: 2, Loss: 11175.774111, lambda^2: 2122.133118
Iteration: 3, Loss: 9873.572337, lambda^2: 552.963735
Iteration: 4, Loss: 9539.284816, lambda^2: 111.025366
Iteration: 5, Loss: 9474.951546, lambda^2: 10.682365
Iteration: 6, Loss: 9469.063523, lambda^2: 0.287819
Iteration: 7, Loss: 9468.854493, lambda^2: 0.014229
Iteration: 8, Loss: 9468.827330, lambda^2: 0.000522
Iteration: 1, Loss: 20318.846169, lambda^2: 16131.409179
Iteration: 2, Loss: 11199.375563, lambda^2: 2121.868977
Iteration: 3, Loss: 9896.186502, lambda^2: 560.216159
Iteration: 4, Loss: 9557.176764, lambda^2: 113.691466
Iteration: 5, Loss: 9491.276665, lambda^2: 11.070332
Iteration: 6, Loss: 9485.172041, lambda^2: 0.307633
Iteration: 7, Loss: 9484.951581, lambda^2: 0.015063
Iteration: 8, Loss: 9484.923224, lambda^2: 0.000583
Iteration: 1, Loss: 20256.043725, lambda^2: 16094.721621
Iteration: 2, Loss: 11148.138948, lambda^2: 2133.073372
Iteration: 3, Loss: 9838.770076, lambda^2: 557.544824
Iteration: 4, Loss: 9501.798954, lambda^2: 111.119786
Iteration: 5, Loss: 9437.516008, lambda^2: 10.391835
Iteration: 6, Loss: 9431.795184, lambda^2: 0.280816
Iteration: 7, Loss: 9431.587496, lambda^2: 0.016744
Iteration: 8, Loss: 9431.557386, lambda^2: 0.000710
Iteration: 1, Loss: 20309.408345, lambda^2: 16168.893008
Iteration: 2, Loss: 11167.220706, lambda^2: 2126.493096
Iteration: 3, Loss: 9861.822171, lambda^2: 557.787369
Iteration: 4, Loss: 9524.325038, lambda^2: 113.411267
Iteration: 5, Loss: 9458.490338, lambda^2: 11.245813
Iteration: 6, Loss: 9452.234652, lambda^2: 0.377597
Iteration: 7, Loss: 9451.936063, lambda^2: 0.024995
Iteration: 8, Loss: 9451.883843, lambda^2: 0.000764
Accuarcy with lambda_ = 0.010000 is 0.152594
Training model with lambda: 0.030000
Iteration: 1, Loss: 20290.091056, lambda^2: 16160.755724
Iteration: 2, Loss: 11146.572639, lambda^2: 2145.418703
Iteration: 3, Loss: 9828.514110, lambda^2: 567.652099
Iteration: 4, Loss: 9484.734056, lambda^2: 115.507055
Iteration: 5, Loss: 9417.627077, lambda^2: 11.105365
Iteration: 6, Loss: 9411.433715, lambda^2: 0.248542
Iteration: 7, Loss: 9411.242442, lambda^2: 0.002324
Iteration: 1, Loss: 20314.125297, lambda^2: 16170.191307
Iteration: 2, Loss: 11167.660739, lambda^2: 2143.707398
Iteration: 3, Loss: 9850.520214, lambda^2: 568.170553
Iteration: 4, Loss: 9506.390548, lambda^2: 115.489228
Iteration: 5, Loss: 9439.335728, lambda^2: 10.874328
Iteration: 6, Loss: 9433.273691, lambda^2: 0.230395
Iteration: 7, Loss: 9433.089125, lambda^2: 0.002265
Iteration: 1, Loss: 20371.496059, lambda^2: 16276.022062
Iteration: 2, Loss: 11175.418258, lambda^2: 2130.311808
Iteration: 3, Loss: 9867.424318, lambda^2: 557.889902
Iteration: 4, Loss: 9530.074210, lambda^2: 110.876379
Iteration: 5, Loss: 9465.763969, lambda^2: 10.219568
Iteration: 6, Loss: 9460.051925, lambda^2: 0.209964
Iteration: 7, Loss: 9459.876654, lambda^2: 0.001864
Iteration: 1, Loss: 20311.730696, lambda^2: 16167.680422
Iteration: 2, Loss: 11169.674064, lambda^2: 2128.735558
Iteration: 3, Loss: 9862.414254, lambda^2: 561.019590
Iteration: 4, Loss: 9522.597854, lambda^2: 114.595734
Iteration: 5, Loss: 9455.955760, lambda^2: 11.092916
Iteration: 6, Loss: 9449.752716, lambda^2: 0.244345
Iteration: 7, Loss: 9449.557560, lambda^2: 0.002149
Iteration: 1, Loss: 20276.467384, lambda^2: 16180.970938
Iteration: 2, Loss: 11121.106927, lambda^2: 2147.526329
Iteration: 3, Loss: 9801.613838, lambda^2: 570.159458
Iteration: 4, Loss: 9455.933783, lambda^2: 118.726262
Iteration: 5, Loss: 9386.606324, lambda^2: 12.730106
Iteration: 6, Loss: 9379.359915, lambda^2: 0.568720
Iteration: 7, Loss: 9378.908034, lambda^2: 0.045633
Iteration: 8, Loss: 9378.823592, lambda^2: 0.001646
Iteration: 1, Loss: 20326.636602, lambda^2: 16193.750413
Iteration: 2, Loss: 11172.848596, lambda^2: 2125.857138
Iteration: 3, Loss: 9867.184431, lambda^2: 562.395940
Iteration: 4, Loss: 9526.347005, lambda^2: 116.151489
Iteration: 5, Loss: 9458.715511, lambda^2: 11.696855
Iteration: 6, Loss: 9452.185484, lambda^2: 0.279599
Iteration: 7, Loss: 9451.980193, lambda^2: 0.001932
Iteration: 1, Loss: 20351.887183, lambda^2: 16309.385702
Iteration: 2, Loss: 11133.343958, lambda^2: 2145.879697
Iteration: 3, Loss: 9814.951777, lambda^2: 568.830378
Iteration: 4, Loss: 9470.290122, lambda^2: 116.556634
Iteration: 5, Loss: 9402.539793, lambda^2: 11.236569
Iteration: 6, Loss: 9396.278207, lambda^2: 0.247797
Iteration: 7, Loss: 9396.086451, lambda^2: 0.002421
Iteration: 1, Loss: 20310.486358, lambda^2: 16121.529802
Iteration: 2, Loss: 11196.023701, lambda^2: 2113.855995
Iteration: 3, Loss: 9898.775980, lambda^2: 551.081356
Iteration: 4, Loss: 9565.469779, lambda^2: 110.059192
Iteration: 5, Loss: 9501.566511, lambda^2: 10.211190
Iteration: 6, Loss: 9495.811614, lambda^2: 0.212217
Iteration: 7, Loss: 9495.612843, lambda^2: 0.001670
Iteration: 1, Loss: 20318.251107, lambda^2: 16168.177785
Iteration: 2, Loss: 11177.155138, lambda^2: 2125.392119
Iteration: 3, Loss: 9872.275187, lambda^2: 557.218282
Iteration: 4, Loss: 9535.057215, lambda^2: 112.519846
Iteration: 5, Loss: 9469.580701, lambda^2: 10.996283
Iteration: 6, Loss: 9463.370038, lambda^2: 0.258852
Iteration: 7, Loss: 9463.145182, lambda^2: 0.001801
Iteration: 1, Loss: 20298.641457, lambda^2: 16134.599076
Iteration: 2, Loss: 11175.166815, lambda^2: 2122.007423
Iteration: 3, Loss: 9872.158975, lambda^2: 559.191263
Iteration: 4, Loss: 9533.390670, lambda^2: 114.699318
Iteration: 5, Loss: 9466.620475, lambda^2: 11.361687
Iteration: 6, Loss: 9460.261243, lambda^2: 0.261088
Iteration: 7, Loss: 9460.057043, lambda^2: 0.002033
Accuarcy with lambda_ = 0.030000 is 0.153669
Training model with lambda: 0.100000
Iteration: 1, Loss: 20256.760662, lambda^2: 16066.242170
Iteration: 2, Loss: 11163.846496, lambda^2: 2136.953030
Iteration: 3, Loss: 9850.130548, lambda^2: 569.297677
Iteration: 4, Loss: 9504.270410, lambda^2: 118.190434
Iteration: 5, Loss: 9434.982001, lambda^2: 11.757137
Iteration: 6, Loss: 9428.253438, lambda^2: 0.239858
Iteration: 7, Loss: 9428.062050, lambda^2: 0.000161
Iteration: 1, Loss: 20299.308965, lambda^2: 16096.897537
Iteration: 2, Loss: 11196.973305, lambda^2: 2114.165272
Iteration: 3, Loss: 9898.873220, lambda^2: 553.076273
Iteration: 4, Loss: 9563.381641, lambda^2: 112.459481
Iteration: 5, Loss: 9497.399660, lambda^2: 10.796800
Iteration: 6, Loss: 9491.086263, lambda^2: 0.201758
Iteration: 7, Loss: 9490.869876, lambda^2: 0.000151
Iteration: 1, Loss: 20338.837246, lambda^2: 16234.824140
Iteration: 2, Loss: 11162.200734, lambda^2: 2127.687717
Iteration: 3, Loss: 9855.659350, lambda^2: 556.818320
Iteration: 4, Loss: 9518.228446, lambda^2: 111.638531
Iteration: 5, Loss: 9452.981780, lambda^2: 10.361376
Iteration: 6, Loss: 9447.045788, lambda^2: 0.182221
Iteration: 7, Loss: 9446.890601, lambda^2: 0.000093
Iteration: 1, Loss: 20313.793172, lambda^2: 16190.589203
Iteration: 2, Loss: 11159.423091, lambda^2: 2130.662595
Iteration: 3, Loss: 9850.631561, lambda^2: 559.653195
Iteration: 4, Loss: 9511.444016, lambda^2: 112.596315
Iteration: 5, Loss: 9445.673422, lambda^2: 10.538201
Iteration: 6, Loss: 9439.682200, lambda^2: 0.183128
Iteration: 7, Loss: 9439.530123, lambda^2: 0.000096
Iteration: 1, Loss: 20371.284072, lambda^2: 16276.623198
Iteration: 2, Loss: 11175.228704, lambda^2: 2128.577746
Iteration: 3, Loss: 9867.373852, lambda^2: 562.324447
Iteration: 4, Loss: 9526.142537, lambda^2: 114.540418
Iteration: 5, Loss: 9459.050661, lambda^2: 10.895715
Iteration: 6, Loss: 9452.785587, lambda^2: 0.202936
Iteration: 7, Loss: 9452.618191, lambda^2: 0.000113
Iteration: 1, Loss: 20310.163326, lambda^2: 16130.446138
Iteration: 2, Loss: 11190.613683, lambda^2: 2112.533085
Iteration: 3, Loss: 9893.888978, lambda^2: 550.537418
Iteration: 4, Loss: 9560.160311, lambda^2: 111.066258
Iteration: 5, Loss: 9495.153816, lambda^2: 10.548846
Iteration: 6, Loss: 9489.099196, lambda^2: 0.196497
Iteration: 7, Loss: 9488.930424, lambda^2: 0.000119
Iteration: 1, Loss: 20317.611687, lambda^2: 16170.279000
Iteration: 2, Loss: 11173.580061, lambda^2: 2130.563412
Iteration: 3, Loss: 9865.112600, lambda^2: 556.532237
Iteration: 4, Loss: 9528.061807, lambda^2: 110.161096
Iteration: 5, Loss: 9463.673869, lambda^2: 10.099516
Iteration: 6, Loss: 9457.875710, lambda^2: 0.177332
Iteration: 7, Loss: 9457.720939, lambda^2: 0.000103
Iteration: 1, Loss: 20303.125045, lambda^2: 16144.724488
Iteration: 2, Loss: 11172.631089, lambda^2: 2134.141643
Iteration: 3, Loss: 9860.676209, lambda^2: 567.891048
Iteration: 4, Loss: 9515.811401, lambda^2: 117.203912
Iteration: 5, Loss: 9447.154634, lambda^2: 11.451681
Iteration: 6, Loss: 9440.615261, lambda^2: 0.224124
Iteration: 7, Loss: 9440.436986, lambda^2: 0.000139
Iteration: 1, Loss: 20300.569116, lambda^2: 16145.232005
Iteration: 2, Loss: 11170.759603, lambda^2: 2122.837455
Iteration: 3, Loss: 9867.008548, lambda^2: 558.050336
Iteration: 4, Loss: 9528.515325, lambda^2: 113.735792
Iteration: 5, Loss: 9461.971003, lambda^2: 10.910297
Iteration: 6, Loss: 9455.741642, lambda^2: 0.203347
Iteration: 7, Loss: 9455.574593, lambda^2: 0.000119
Iteration: 1, Loss: 20284.179191, lambda^2: 16111.305569
Iteration: 2, Loss: 11170.211790, lambda^2: 2128.049809
Iteration: 3, Loss: 9862.982648, lambda^2: 559.455251
Iteration: 4, Loss: 9523.765982, lambda^2: 112.736049
Iteration: 5, Loss: 9457.903543, lambda^2: 10.506003
Iteration: 6, Loss: 9451.901672, lambda^2: 0.185266
Iteration: 7, Loss: 9451.741807, lambda^2: 0.000100
Accuarcy with lambda_ = 0.100000 is 0.150414
Training model with lambda: 0.300000
Iteration: 1, Loss: 20289.388359, lambda^2: 16168.039280
Iteration: 2, Loss: 11139.688588, lambda^2: 2149.523859
Iteration: 3, Loss: 9817.356306, lambda^2: 567.768282
Iteration: 4, Loss: 9471.799883, lambda^2: 114.086591
Iteration: 5, Loss: 9404.235950, lambda^2: 10.498548
Iteration: 6, Loss: 9397.936495, lambda^2: 0.177773
Iteration: 7, Loss: 9397.766272, lambda^2: 0.000077
Iteration: 1, Loss: 20296.829638, lambda^2: 16171.653156
Iteration: 2, Loss: 11150.320517, lambda^2: 2127.201685
Iteration: 3, Loss: 9843.234564, lambda^2: 553.368077
Iteration: 4, Loss: 9506.820821, lambda^2: 110.227634
Iteration: 5, Loss: 9441.568603, lambda^2: 10.262794
Iteration: 6, Loss: 9435.445414, lambda^2: 0.177962
Iteration: 7, Loss: 9435.281455, lambda^2: 0.000080
Iteration: 1, Loss: 20295.278892, lambda^2: 16148.004869
Iteration: 2, Loss: 11160.548155, lambda^2: 2131.593034
Iteration: 3, Loss: 9850.003316, lambda^2: 559.597477
Iteration: 4, Loss: 9509.480931, lambda^2: 112.093770
Iteration: 5, Loss: 9443.129726, lambda^2: 10.254745
Iteration: 6, Loss: 9436.998851, lambda^2: 0.173203
Iteration: 7, Loss: 9436.836035, lambda^2: 0.000076
Iteration: 1, Loss: 20308.030175, lambda^2: 16195.778964
Iteration: 2, Loss: 11146.081934, lambda^2: 2142.472763
Iteration: 3, Loss: 9828.699528, lambda^2: 562.462442
Iteration: 4, Loss: 9486.679578, lambda^2: 111.948230
Iteration: 5, Loss: 9420.482238, lambda^2: 10.114735
Iteration: 6, Loss: 9414.417408, lambda^2: 0.166125
Iteration: 7, Loss: 9414.257393, lambda^2: 0.000068
Iteration: 1, Loss: 20334.839087, lambda^2: 16189.267296
Iteration: 2, Loss: 11184.487274, lambda^2: 2120.127879
Iteration: 3, Loss: 9880.736244, lambda^2: 558.196644
Iteration: 4, Loss: 9541.009007, lambda^2: 112.616569
Iteration: 5, Loss: 9474.383987, lambda^2: 10.523674
Iteration: 6, Loss: 9468.126147, lambda^2: 0.184129
Iteration: 7, Loss: 9467.959577, lambda^2: 0.000084
Iteration: 1, Loss: 20351.592013, lambda^2: 16229.606778
Iteration: 2, Loss: 11180.287928, lambda^2: 2124.019896
Iteration: 3, Loss: 9874.190841, lambda^2: 558.132992
Iteration: 4, Loss: 9534.780761, lambda^2: 110.081233
Iteration: 5, Loss: 9469.738017, lambda^2: 9.654568
Iteration: 6, Loss: 9463.948274, lambda^2: 0.148554
Iteration: 7, Loss: 9463.800690, lambda^2: 0.000052
Iteration: 1, Loss: 20319.923127, lambda^2: 16125.044880
Iteration: 2, Loss: 11200.399905, lambda^2: 2128.075065
Iteration: 3, Loss: 9891.459164, lambda^2: 561.030141
Iteration: 4, Loss: 9550.103848, lambda^2: 111.397264
Iteration: 5, Loss: 9484.223866, lambda^2: 9.850690
Iteration: 6, Loss: 9478.320278, lambda^2: 0.152968
Iteration: 7, Loss: 9478.172306, lambda^2: 0.000055
Iteration: 1, Loss: 20336.140187, lambda^2: 16250.313397
Iteration: 2, Loss: 11149.337092, lambda^2: 2134.515590
Iteration: 3, Loss: 9836.433205, lambda^2: 564.638332
Iteration: 4, Loss: 9492.160980, lambda^2: 116.833940
Iteration: 5, Loss: 9422.719647, lambda^2: 11.568320
Iteration: 6, Loss: 9415.798783, lambda^2: 0.225118
Iteration: 7, Loss: 9415.597626, lambda^2: 0.000127
Iteration: 1, Loss: 20328.374563, lambda^2: 16221.620488
Iteration: 2, Loss: 11154.358085, lambda^2: 2143.682467
Iteration: 3, Loss: 9835.571588, lambda^2: 568.889663
Iteration: 4, Loss: 9489.223563, lambda^2: 115.866354
Iteration: 5, Loss: 9420.707336, lambda^2: 10.910690
Iteration: 6, Loss: 9414.241479, lambda^2: 0.194567
Iteration: 7, Loss: 9414.071314, lambda^2: 0.000094
Iteration: 1, Loss: 20332.903980, lambda^2: 16210.825937
Iteration: 2, Loss: 11168.145104, lambda^2: 2129.573493
Iteration: 3, Loss: 9858.768718, lambda^2: 558.921825
Iteration: 4, Loss: 9518.819271, lambda^2: 111.495419
Iteration: 5, Loss: 9452.866230, lambda^2: 10.030826
Iteration: 6, Loss: 9446.698691, lambda^2: 0.167217
Iteration: 7, Loss: 9446.465289, lambda^2: 0.000105
Accuarcy with lambda_ = 0.300000 is 0.152963
Training model with lambda: 1.000000
Iteration: 1, Loss: 20323.438572, lambda^2: 16149.559019
Iteration: 2, Loss: 11189.882268, lambda^2: 2119.269539
Iteration: 3, Loss: 9884.264987, lambda^2: 550.226579
Iteration: 4, Loss: 9546.880805, lambda^2: 106.578238
Iteration: 5, Loss: 9481.937476, lambda^2: 8.952694
Iteration: 6, Loss: 9475.902895, lambda^2: 0.121464
Iteration: 7, Loss: 9475.714429, lambda^2: 0.000032
Iteration: 1, Loss: 20321.944738, lambda^2: 16172.631660
Iteration: 2, Loss: 11176.794542, lambda^2: 2116.260088
Iteration: 3, Loss: 9873.003998, lambda^2: 549.346574
Iteration: 4, Loss: 9536.180037, lambda^2: 106.859331
Iteration: 5, Loss: 9471.321579, lambda^2: 9.129453
Iteration: 6, Loss: 9465.338558, lambda^2: 0.130115
Iteration: 7, Loss: 9465.156760, lambda^2: 0.000038
Iteration: 1, Loss: 20310.379796, lambda^2: 16125.470524
Iteration: 2, Loss: 11192.720065, lambda^2: 2103.495914
Iteration: 3, Loss: 9897.812739, lambda^2: 544.244803
Iteration: 4, Loss: 9564.458697, lambda^2: 105.655696
Iteration: 5, Loss: 9500.414829, lambda^2: 9.024831
Iteration: 6, Loss: 9494.516485, lambda^2: 0.131841
Iteration: 7, Loss: 9494.337372, lambda^2: 0.000041
Iteration: 1, Loss: 20285.816358, lambda^2: 16058.417760
Iteration: 2, Loss: 11202.760288, lambda^2: 2103.541521
Iteration: 3, Loss: 9907.149856, lambda^2: 544.884330
Iteration: 4, Loss: 9573.311283, lambda^2: 104.166758
Iteration: 5, Loss: 9510.241762, lambda^2: 8.325390
Iteration: 6, Loss: 9504.761099, lambda^2: 0.102204
Iteration: 7, Loss: 9504.608488, lambda^2: 0.000022
Iteration: 1, Loss: 20321.472959, lambda^2: 16222.749198
Iteration: 2, Loss: 11148.369664, lambda^2: 2123.361827
Iteration: 3, Loss: 9839.986994, lambda^2: 551.774562
Iteration: 4, Loss: 9501.292622, lambda^2: 107.762354
Iteration: 5, Loss: 9435.583636, lambda^2: 9.391183
Iteration: 6, Loss: 9429.363574, lambda^2: 0.142131
Iteration: 7, Loss: 9429.164431, lambda^2: 0.000048
Iteration: 1, Loss: 20294.100881, lambda^2: 16174.541634
Iteration: 2, Loss: 11143.837943, lambda^2: 2127.651669
Iteration: 3, Loss: 9832.648439, lambda^2: 557.195831
Iteration: 4, Loss: 9490.708304, lambda^2: 111.217122
Iteration: 5, Loss: 9423.118835, lambda^2: 10.021404
Iteration: 6, Loss: 9416.593732, lambda^2: 0.155988
Iteration: 7, Loss: 9416.387246, lambda^2: 0.000053
Iteration: 1, Loss: 20339.322626, lambda^2: 16217.669369
Iteration: 2, Loss: 11170.009762, lambda^2: 2127.061289
Iteration: 3, Loss: 9858.867338, lambda^2: 559.076665
Iteration: 4, Loss: 9515.754887, lambda^2: 111.374203
Iteration: 5, Loss: 9448.058499, lambda^2: 10.079500
Iteration: 6, Loss: 9441.483163, lambda^2: 0.166710
Iteration: 7, Loss: 9441.265328, lambda^2: 0.000068
Iteration: 1, Loss: 20313.790785, lambda^2: 16179.646588
Iteration: 2, Loss: 11161.759416, lambda^2: 2130.046814
Iteration: 3, Loss: 9848.595603, lambda^2: 559.014737
Iteration: 4, Loss: 9505.526226, lambda^2: 110.227126
Iteration: 5, Loss: 9438.504614, lambda^2: 9.632503
Iteration: 6, Loss: 9432.168641, lambda^2: 0.147494
Iteration: 7, Loss: 9431.965591, lambda^2: 0.000052
Iteration: 1, Loss: 20331.787275, lambda^2: 16204.982474
Iteration: 2, Loss: 11168.801037, lambda^2: 2123.248941
Iteration: 3, Loss: 9860.652634, lambda^2: 553.677830
Iteration: 4, Loss: 9521.024369, lambda^2: 109.123571
Iteration: 5, Loss: 9454.477457, lambda^2: 9.701162
Iteration: 6, Loss: 9448.004656, lambda^2: 0.148897
Iteration: 7, Loss: 9447.790775, lambda^2: 0.000050
Iteration: 1, Loss: 20312.612878, lambda^2: 16197.453583
Iteration: 2, Loss: 11149.443836, lambda^2: 2135.708822
Iteration: 3, Loss: 9833.216437, lambda^2: 557.747828
Iteration: 4, Loss: 9491.185484, lambda^2: 109.965465
Iteration: 5, Loss: 9424.547462, lambda^2: 9.731636
Iteration: 6, Loss: 9418.262467, lambda^2: 0.149627
Iteration: 7, Loss: 9418.070202, lambda^2: 0.000051
Accuarcy with lambda_ = 1.000000 is 0.151919
Training model with lambda: 3.000000
Iteration: 1, Loss: 20315.120960, lambda^2: 16131.741116
Iteration: 2, Loss: 11189.591561, lambda^2: 2098.130448
Iteration: 3, Loss: 9891.534903, lambda^2: 537.610622
Iteration: 4, Loss: 9556.504280, lambda^2: 100.877013
Iteration: 5, Loss: 9491.903466, lambda^2: 7.836807
Iteration: 6, Loss: 9485.618520, lambda^2: 0.090882
Iteration: 7, Loss: 9485.360728, lambda^2: 0.000017
Iteration: 1, Loss: 20321.929069, lambda^2: 16258.647454
Iteration: 2, Loss: 11121.479385, lambda^2: 2130.798316
Iteration: 3, Loss: 9801.905363, lambda^2: 553.389881
Iteration: 4, Loss: 9456.446071, lambda^2: 107.755210
Iteration: 5, Loss: 9387.265609, lambda^2: 9.296020
Iteration: 6, Loss: 9379.942138, lambda^2: 0.135715
Iteration: 7, Loss: 9379.605733, lambda^2: 0.000042
Iteration: 1, Loss: 20312.383278, lambda^2: 16182.408541
Iteration: 2, Loss: 11156.132119, lambda^2: 2116.848230
Iteration: 3, Loss: 9845.229250, lambda^2: 549.802631
Iteration: 4, Loss: 9501.616046, lambda^2: 106.527362
Iteration: 5, Loss: 9432.964782, lambda^2: 8.942181
Iteration: 6, Loss: 9425.788066, lambda^2: 0.123526
Iteration: 7, Loss: 9425.462780, lambda^2: 0.000034
Iteration: 1, Loss: 20347.426435, lambda^2: 16222.421020
Iteration: 2, Loss: 11171.514058, lambda^2: 2117.701898
Iteration: 3, Loss: 9860.330465, lambda^2: 547.910689
Iteration: 4, Loss: 9518.549896, lambda^2: 105.237358
Iteration: 5, Loss: 9451.140591, lambda^2: 8.745072
Iteration: 6, Loss: 9444.268765, lambda^2: 0.113881
Iteration: 7, Loss: 9443.975491, lambda^2: 0.000026
Iteration: 1, Loss: 20321.914148, lambda^2: 16151.392903
Iteration: 2, Loss: 11185.361226, lambda^2: 2097.356646
Iteration: 3, Loss: 9888.153855, lambda^2: 533.286144
Iteration: 4, Loss: 9555.977731, lambda^2: 99.990855
Iteration: 5, Loss: 9492.065570, lambda^2: 7.971216
Iteration: 6, Loss: 9485.806263, lambda^2: 0.096028
Iteration: 7, Loss: 9485.551762, lambda^2: 0.000019
Iteration: 1, Loss: 20331.517597, lambda^2: 16145.359421
Iteration: 2, Loss: 11198.139381, lambda^2: 2105.171167
Iteration: 3, Loss: 9895.051790, lambda^2: 542.574180
Iteration: 4, Loss: 9556.473169, lambda^2: 103.111099
Iteration: 5, Loss: 9490.199836, lambda^2: 8.329156
Iteration: 6, Loss: 9483.523153, lambda^2: 0.104403
Iteration: 7, Loss: 9483.236729, lambda^2: 0.000023
Iteration: 1, Loss: 20312.824255, lambda^2: 16170.505862
Iteration: 2, Loss: 11164.972852, lambda^2: 2104.380957
Iteration: 3, Loss: 9862.315551, lambda^2: 541.154418
Iteration: 4, Loss: 9525.139647, lambda^2: 101.583093
Iteration: 5, Loss: 9460.306122, lambda^2: 7.779111
Iteration: 6, Loss: 9454.139527, lambda^2: 0.085223
Iteration: 7, Loss: 9453.900374, lambda^2: 0.000014
Iteration: 1, Loss: 20338.776908, lambda^2: 16186.244479
Iteration: 2, Loss: 11185.205321, lambda^2: 2099.194175
Iteration: 3, Loss: 9886.494551, lambda^2: 535.030438
Iteration: 4, Loss: 9553.125528, lambda^2: 99.306485
Iteration: 5, Loss: 9489.568669, lambda^2: 7.670232
Iteration: 6, Loss: 9483.492586, lambda^2: 0.085415
Iteration: 7, Loss: 9483.254491, lambda^2: 0.000014
Iteration: 1, Loss: 20327.504714, lambda^2: 16207.239244
Iteration: 2, Loss: 11158.867024, lambda^2: 2112.873538
Iteration: 3, Loss: 9851.657022, lambda^2: 541.702896
Iteration: 4, Loss: 9514.343411, lambda^2: 101.778437
Iteration: 5, Loss: 9449.131552, lambda^2: 8.111381
Iteration: 6, Loss: 9442.707360, lambda^2: 0.097712
Iteration: 7, Loss: 9442.445206, lambda^2: 0.000019
Iteration: 1, Loss: 20331.503471, lambda^2: 16186.664587
Iteration: 2, Loss: 11177.121132, lambda^2: 2099.069627
Iteration: 3, Loss: 9878.388159, lambda^2: 535.003430
Iteration: 4, Loss: 9544.857306, lambda^2: 100.204987
Iteration: 5, Loss: 9480.665345, lambda^2: 8.057282
Iteration: 6, Loss: 9474.322113, lambda^2: 0.100512
Iteration: 7, Loss: 9474.057258, lambda^2: 0.000022
Accuarcy with lambda_ = 3.000000 is 0.152871
Training model with lambda: 10.000000
Iteration: 1, Loss: 20318.404344, lambda^2: 16131.868956
Iteration: 2, Loss: 11180.994206, lambda^2: 2072.443864
Iteration: 3, Loss: 9881.874934, lambda^2: 515.689209
Iteration: 4, Loss: 9545.269724, lambda^2: 90.580516
Iteration: 5, Loss: 9478.122997, lambda^2: 6.044436
Iteration: 6, Loss: 9470.404824, lambda^2: 0.047271
Iteration: 7, Loss: 9469.998863, lambda^2: 0.000004
Iteration: 1, Loss: 20330.230681, lambda^2: 16149.264593
Iteration: 2, Loss: 11185.755972, lambda^2: 2066.956735
Iteration: 3, Loss: 9891.137302, lambda^2: 507.063338
Iteration: 4, Loss: 9560.607419, lambda^2: 86.188537
Iteration: 5, Loss: 9496.602459, lambda^2: 5.406900
Iteration: 6, Loss: 9489.560676, lambda^2: 0.037193
Iteration: 7, Loss: 9489.212437, lambda^2: 0.000002
Iteration: 1, Loss: 20303.236040, lambda^2: 16109.964873
Iteration: 2, Loss: 11176.070127, lambda^2: 2073.267810
Iteration: 3, Loss: 9876.463828, lambda^2: 514.087117
Iteration: 4, Loss: 9541.058365, lambda^2: 89.664600
Iteration: 5, Loss: 9474.656956, lambda^2: 5.904563
Iteration: 6, Loss: 9467.117876, lambda^2: 0.044535
Iteration: 7, Loss: 9466.728413, lambda^2: 0.000003
Iteration: 1, Loss: 20280.561590, lambda^2: 16087.188465
Iteration: 2, Loss: 11162.094060, lambda^2: 2080.867246
Iteration: 3, Loss: 9857.076096, lambda^2: 516.193066
Iteration: 4, Loss: 9519.568216, lambda^2: 89.990960
Iteration: 5, Loss: 9452.591336, lambda^2: 5.845859
Iteration: 6, Loss: 9445.017272, lambda^2: 0.042680
Iteration: 7, Loss: 9444.632609, lambda^2: 0.000003
Iteration: 1, Loss: 20344.345854, lambda^2: 16133.332265
Iteration: 2, Loss: 11210.957785, lambda^2: 2056.947799
Iteration: 3, Loss: 9922.671951, lambda^2: 503.275011
Iteration: 4, Loss: 9594.664215, lambda^2: 85.203012
Iteration: 5, Loss: 9531.419089, lambda^2: 5.237335
Iteration: 6, Loss: 9524.563165, lambda^2: 0.033901
Iteration: 7, Loss: 9524.235542, lambda^2: 0.000002
Iteration: 1, Loss: 20291.881277, lambda^2: 16064.820394
Iteration: 2, Loss: 11189.804324, lambda^2: 2061.664246
Iteration: 3, Loss: 9898.095877, lambda^2: 504.114668
Iteration: 4, Loss: 9569.238008, lambda^2: 85.867557
Iteration: 5, Loss: 9505.599950, lambda^2: 5.381303
Iteration: 6, Loss: 9498.651587, lambda^2: 0.035731
Iteration: 7, Loss: 9498.314874, lambda^2: 0.000002
Iteration: 1, Loss: 20293.875777, lambda^2: 16075.518176
Iteration: 2, Loss: 11186.587188, lambda^2: 2067.871725
Iteration: 3, Loss: 9890.484740, lambda^2: 512.660692
Iteration: 4, Loss: 9556.011666, lambda^2: 88.265405
Iteration: 5, Loss: 9490.538401, lambda^2: 5.521441
Iteration: 6, Loss: 9483.353719, lambda^2: 0.037675
Iteration: 7, Loss: 9483.002716, lambda^2: 0.000002
Iteration: 1, Loss: 20308.987343, lambda^2: 16178.815090
Iteration: 2, Loss: 11140.903119, lambda^2: 2093.653890
Iteration: 3, Loss: 9827.733430, lambda^2: 524.268240
Iteration: 4, Loss: 9485.252476, lambda^2: 92.345683
Iteration: 5, Loss: 9416.668824, lambda^2: 6.085497
Iteration: 6, Loss: 9408.857572, lambda^2: 0.045360
Iteration: 7, Loss: 9408.459107, lambda^2: 0.000003
Iteration: 1, Loss: 20306.563455, lambda^2: 16151.970603
Iteration: 2, Loss: 11153.412263, lambda^2: 2090.028740
Iteration: 3, Loss: 9842.630454, lambda^2: 519.515849
Iteration: 4, Loss: 9503.100402, lambda^2: 90.129155
Iteration: 5, Loss: 9436.065888, lambda^2: 5.845378
Iteration: 6, Loss: 9428.524101, lambda^2: 0.043407
Iteration: 7, Loss: 9428.138645, lambda^2: 0.000003
Iteration: 1, Loss: 20322.338048, lambda^2: 16134.163963
Iteration: 2, Loss: 11185.108155, lambda^2: 2069.348107
Iteration: 3, Loss: 9888.520413, lambda^2: 511.938311
Iteration: 4, Loss: 9554.618164, lambda^2: 89.283692
Iteration: 5, Loss: 9488.460125, lambda^2: 5.918200
Iteration: 6, Loss: 9480.897866, lambda^2: 0.045457
Iteration: 7, Loss: 9480.503364, lambda^2: 0.000003
Accuarcy with lambda_ = 10.000000 is 0.155695
CV done. The accuarcy list is:
[array([ 0.15465152]), array([ 0.14921707]), array([ 0.15259441]), array([ 0.15366902]), array([ 0.15041449]), array([ 0.15296285]), array([ 0.15191894]), array([ 0.15287074]), array([ 0.15569543])]

